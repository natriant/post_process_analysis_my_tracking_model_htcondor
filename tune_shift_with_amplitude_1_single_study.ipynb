{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script is used to plot the tune shift with amplitude.\n",
    "- For the tune calculation the NAFF algorithm is used.\n",
    "- Be careful each time to introduce the configuration file you need along with the file that contains the turn by turn data (from /afs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from math import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import NAFFlib as pnf\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test that you have acces to the /afs directory where your data are stored\n",
    "If permision denied\n",
    "- $USERNAME@CERN.CH \n",
    "- aklog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mmy_tracking_model_htcondor\u001b[0m/  \u001b[01;34msimulation_data_2018\u001b[0m/  \u001b[01;34msixdesk\u001b[0m/  \u001b[01;34mworkspaces\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls /afs/cern.ch/work/n/natriant/private"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'legend.fontsize': 12,\n",
    "          'figure.figsize': (8.5, 6.5),\n",
    "          'axes.labelsize': 25,\n",
    "          'axes.titlesize': 25,\n",
    "          'xtick.labelsize': 25,\n",
    "          'ytick.labelsize': 25,\n",
    "          'image.cmap': 'jet',\n",
    "          'lines.linewidth': 1,\n",
    "          'lines.markersize': 5,\n",
    "          'font.family': 'sans-serif'}\n",
    "\n",
    "plt.rc('text', usetex=False)\n",
    "plt.rc('font', family='serif')\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the parameters of the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "with open('./configuration_files/config_octupole.json', \"r\") as read_file:\n",
    "        data = json.load(read_file)\n",
    "my_afs_path = '/afs/cern.ch/work/n/natriant/private/my_tracking_model_htcondor/tracking_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the set of parameters of the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delta = 0.1\n",
    "version = 2\n",
    "ksi = 0.005\n",
    "file_name = 'Qx62.775_Qy62.775_detunerx5825.61_detunery0.0_g0.200_delta0.100_betax115.75_betay115.75_particles15000_turns1000_aperture3e-2'\n",
    "df = pd.read_pickle(my_afs_path+ file_name+ '.pkl')#.format(Delta, version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune shift with amplitude\n",
    "- We need to store the data in groups of particles. \n",
    "- In our data frames are in groups of turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = {}\n",
    "px_data = {}\n",
    "y_data = {}\n",
    "py_data = {}\n",
    "for particle in range(data['study_parameters']['particles']):\n",
    "    x_data[particle] = []\n",
    "    px_data[particle] = []\n",
    "    y_data[particle] = []\n",
    "    py_data[particle] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 turns should be enough\n",
    "turns = 1000 \n",
    "for particle in range(data['study_parameters']['particles']):\n",
    "    #for turn in range(data['study_parameters']['turns']):\n",
    "    for turn in range(turns):\n",
    "        x_data[particle].append(df.at[turn,'x'][particle])\n",
    "        px_data[particle].append(df.at[turn,'px'][particle])\n",
    "        y_data[particle].append(df.at[turn,'y'][particle])\n",
    "        py_data[particle].append(df.at[turn,'py'][particle])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude the particles that are lost, otherwise NAFF crashes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lost_particles = []\n",
    "Qx_list = []\n",
    "Qy_list = []\n",
    "\n",
    "for particle in range(data['study_parameters']['particles']):\n",
    "    if np.isnan(x_data[particle]).any() or np.isnan(px_data[particle]).any():\n",
    "        lost_particles.append(particle)\n",
    "        print('particle {} lost'.format(particle))\n",
    "    else:        \n",
    "        signal_x = x_data[particle]  \n",
    "        signal_y = y_data[particle] \n",
    "\n",
    "        Qx_list.append(pnf.get_tune(np.array(signal_x)))\n",
    "        Qy_list.append(pnf.get_tune(np.array(signal_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use normalised coordiantes (same applies for y)\n",
    "\\begin{equation}\n",
    "x_{N} = \\frac{x}{\\sqrt{\\beta(s)}} \\\\\n",
    "px_{N} = px \\cdot \\sqrt{\\beta(s)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate initial actions Jx (same applies for y)\n",
    "\\begin{equation}\n",
    "J_x = \\frac{x_{N}^2 + px_{N}^2}{2} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_initial_actions = False\n",
    "if flag_initial_actions :\n",
    "    x_norm = df.at[0,'x']/sqrt(data['machine_parameters']['beta_x']) # the index 0 corresponds to turn\n",
    "    px_norm = df.at[0,'px']*sqrt(data['machine_parameters']['beta_x'])\n",
    "    Jx_initial = (x_norm**2 + px_norm**2)/2.\n",
    "\n",
    "    y_norm = df.at[0,'y']/sqrt(data['machine_parameters']['beta_y']) # the index 0 corresponds to turn\n",
    "    py_norm = df.at[0,'py']*sqrt(data['machine_parameters']['beta_y'])\n",
    "    Jy_initial = (y_norm**2 + py_norm**2)/2.\n",
    "    \n",
    "    print('The maximum initial actions: \\nJx ={} \\nJy={}'.format(max(Jx_initial), max(Jy_initial)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the average actions for the first 1000 turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_average_actions = True\n",
    "if flag_average_actions:\n",
    "    Jx_mean = [] # Here you will save the average actions for each particle over the first and last 1000 turns\n",
    "    Jx_data = {}\n",
    "    Jy_mean = [] # Here you will save the average actions for each particle over the first and last 1000 turns\n",
    "    Jy_data = {}\n",
    "    for particle in range(data['study_parameters']['particles']):\n",
    "        Jx_data[particle] = []\n",
    "        Jx_data[particle] = (np.array(x_data[particle])/sqrt(data['machine_parameters']['beta_x']))**2 + (np.array(px_data[particle])*sqrt(data['machine_parameters']['beta_x']))**2\n",
    "        Jx_mean.append(np.nanmean(Jx_data[particle]))\n",
    "               \n",
    "        \n",
    "        Jy_data[particle] = []\n",
    "        Jy_data[particle] = (np.array(y_data[particle])/sqrt(data['machine_parameters']['beta_y']))**2 + (np.array(py_data[particle])*sqrt(data['machine_parameters']['beta_y']))**2\n",
    "        Jy_mean.append(np.nanmean(Jy_data[particle]))\n",
    "        \n",
    "    print('The maximum mean actions: \\nJx ={} \\nJy={}'.format(max(Jx_mean), max(Jy_mean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(8,7))\n",
    "\n",
    "Qx_list_plot = [1-i for i in Qx_list] # 1-i becuase the tune is above 0.5\n",
    "Qy_list_plot = [1-i for i in Qy_list]\n",
    "\n",
    "ax.scatter(np.array(Jx_mean)*1e9, Qx_list_plot, c='b', label=r'$Q_x$') \n",
    "ax.scatter(np.array(Jy_mean)*1e9, Qy_list_plot, c='r', label=r'$Q_y$') \n",
    "ax.set_title(r'$\\Delta={}, g={}, \\xi={} $'.format(Delta, 0.2,0.005))\n",
    "ax.set_xlabel(r'$2J_{x,y}$'+r'$\\cdot 10^{-9}$')\n",
    "ax.set_ylabel(r'$Q_{x,y}$')\n",
    "ax.set_ylim(0.765, 0.785)\n",
    "ax.set_xlim(0,9)\n",
    "ax.grid()\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "savefig = False\n",
    "if savefig:\n",
    "    plt.savefig('./figures/tune_shift_{}.png'.format(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(8,7))\n",
    "\n",
    "Qx_list_plot = [1-i for i in Qx_list] # 1-i becuase the tune is above 0.5\n",
    "Qy_list_plot = [1-i for i in Qy_list]\n",
    "\n",
    "ax.scatter( Qx_list_plot, Qy_list_plot, c='k')\n",
    "ax.set_title(r'$\\Delta={}, g={}, \\xi={}$'.format(Delta, 0.2, 0.00))\n",
    "ax.set_xlabel(r'$Q_{x}$')\n",
    "ax.set_ylabel(r'$Q_{y}$')\n",
    "ax.set_ylim(0.765, 0.785)\n",
    "ax.set_xlim(0.765, 0.785)\n",
    "\n",
    "ax.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "savefig = False\n",
    "if savefig:\n",
    "    plt.savefig('./figures/footprint_{}.png'.format(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
